{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        新车指导价       车系 变速器类型  驱动形式 国产进口合资 燃料类型 交易城市 价格类型  车龄      平均里程  过户次数\n",
      "239609   7.99       逸动    手动  前置前驱     国产   汽油   青岛  B2C   6  1.000000     0\n",
      "353260  36.99  凯迪拉克XTS    自动  前置前驱     合资   汽油   昆明  C2B   4  1.095000     0\n",
      "265397  43.99  牧马人(进口)    自动  前置四驱     进口   汽油   临沂  B2C   6  1.333333     0\n",
      "122804  15.70    新世代全顺    手动  前置后驱     合资   柴油   武汉  B2C   4  0.750000     0\n",
      "61114   46.80     奔驰E级    自动  前置后驱     合资   汽油   广州  B2C   5  1.638000     0\n",
      "...       ...      ...   ...   ...    ...  ...  ...  ...  ..       ...   ...\n",
      "226552  13.08       雷凌  无级变速  前置前驱     合资   汽油  哈尔滨  B2C   4  0.732500     0\n",
      "33209   13.48      卡罗拉  无级变速  前置前驱     合资   汽油   钦州  B2C   5  1.240000     0\n",
      "62604   48.80     奔驰E级    自动  前置后驱     合资   汽油   深圳  C2B   5  0.760000     0\n",
      "42852   41.53    奥迪A6L   双离合  前置前驱     合资   汽油   潍坊  B2C   4  2.400000     0\n",
      "177895   7.48       雨燕    自动  前置前驱     合资   汽油   廊坊  B2B   5  1.544000     1\n",
      "\n",
      "[159389 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "from torch import nn\n",
    "from numpy.random import permutation\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# hyperparameter setting:\n",
    "TrainRatio = 4/5\n",
    "ValiRatio = 1/5\n",
    "\n",
    "# read csv\n",
    "# fpath = \"./datas/ml-latest-small/ratings.csv\" # 注意当前路径需要是datas上一级路径\n",
    "# DataSet = pd.read_csv(fpath)\n",
    "# read xlsx\n",
    "fpath = \"/Users/yun/Desktop/OA_残值估值/中汽研二手车数据/feature_1020.xlsx\"\n",
    "DataSet = pd.read_excel(fpath)\n",
    "\n",
    "# 数据清洗，离群点去噪\n",
    "def Outlier_Delete(DataSet, Series_name ,t_stud=3):\n",
    "    '''\n",
    "    按照正态分布的末端值去除离群点\n",
    "    Input：DataFrame DataSet ； 针对对象列； t-student 的值，一般取3，可调整正常值范围\n",
    "    Output：用该对象列去除离群点后的数据集\n",
    "    '''\n",
    "    DataSet = DataSet.sort_values(by=Series_name)\n",
    "    mean = DataSet[Series_name].mean()\n",
    "    sigma = DataSet[Series_name].std()\n",
    "    # 筛选异常值\n",
    "    DataSet_new = DataSet.loc[( mean-t_stud*sigma < DataSet[Series_name]) & (DataSet[Series_name]  < mean+t_stud*sigma) , :]\n",
    "    return DataSet_new\n",
    "\n",
    "DataSet_new = Outlier_Delete(DataSet, '新车指导价', 0.618)\n",
    "# 以新车指导价对样本进行去噪，留下大概只有指导价150w以内的样本\n",
    "DataSet_new2 = Outlier_Delete(DataSet_new, '车龄', 0.618)\n",
    "# 以车龄对样本进行去噪，留下大概只有19年以内的样本\n",
    "DataSet_new3 = Outlier_Delete(DataSet_new2, '过户次数', 6)\n",
    "# 以过户次数对样本进行去噪，留下大概只有指导价5次以内的样本\n",
    "DataSet = Outlier_Delete(DataSet_new3, '平均里程', 4)\n",
    "# 以平均里程数对样本进行去噪，留下大概只有指导价5次以内的样本\n",
    "# 以上留下多少，用Outlier_Delete最后一个参数可调整\n",
    "DataSet = shuffle(DataSet)\n",
    "\n",
    "\n",
    "\n",
    "nData = len(DataSet)\n",
    "nTrain = TrainRatio * nData\n",
    "nVali = ValiRatio * nData\n",
    "train_data = DataSet.iloc[0:int(nTrain)]\n",
    "test_data =DataSet.iloc[int(nTrain):nData]\n",
    "# test_data =DataSet[nTrain+nVali:-1]\n",
    "guideprice_test = test_data['新车指导价'].values.reshape(-1, 1)\n",
    "\n",
    "# testset的新车指导价\n",
    "# preprocess\n",
    "all_features = pd.concat((train_data.iloc[:, 0:-1], test_data.iloc[:, 0:-1]))\n",
    "print(all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 训练log rmse: 0.166212, 测试log rmse: 0.183189,\n",
      "[ 8.340372   9.611574   3.7082052 ... 27.446644  25.006922   3.8791473]\n",
      "[[16.78]\n",
      " [19.28]\n",
      " [12.48]\n",
      " ...\n",
      " [48.8 ]\n",
      " [41.53]\n",
      " [ 7.48]]\n"
     ]
    }
   ],
   "source": [
    "# process numerical variable\n",
    "# normalization\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "# feature为数值的列索引, 注意object即为字符串类型\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 在标准化数据之后均值为0，因此我们可以将缺失值设置为0（均值）\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "# process discrete variable\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "# One-hot code\n",
    "# `Dummy_na=True` 将“na”（缺失值）视为有效的特征值，并为其创建指示符特征。\n",
    "\n",
    "\n",
    "train_features = torch.tensor(all_features.iloc[0:int(nTrain)].values, dtype=d2l.float32)\n",
    "test_features = torch.tensor(all_features.iloc[int(nTrain):].values, dtype=d2l.float32)\n",
    "# 通过value属性提取pandas中的numpy格式并将其转换为torch中的张量, 注意我们已经把所有类型都转成数值型数据了。\n",
    "train_labels = torch.tensor(\n",
    "    train_data['交易价格'].values.reshape(-1, 1), dtype=d2l.float32)\n",
    "test_labels = torch.tensor(\n",
    "    test_data['交易价格'].values.reshape(-1, 1), dtype=d2l.float32)\n",
    "# 提取标签并转换成列张量\n",
    "\n",
    "# 定义模型\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# 定义损失函数\n",
    "in_features = train_features.shape[1]\n",
    "# feature数量\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(in_features,1))\n",
    "    return net\n",
    "\n",
    "# 定义线性模型：单层网络，全连接层单输出；\n",
    "def log_rmse(net, features, labels):\n",
    "    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
    "    rmse = torch.sqrt(loss(torch.log(clipped_preds),\n",
    "                           torch.log(labels)))\n",
    "    return rmse.item()\n",
    "# 定义衡量指标，注意我们还是用MSE当作损失函数来优化，这个log_rmse只是衡量指标。\n",
    "\n",
    "# 定义训练器\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    '''\n",
    "\n",
    "    :param net: 定义好的神经网络\n",
    "    :param train_features: 训练集（不是原始数据集）的feature\n",
    "    :param train_labels: 训练集（不是原始数据集）的label\n",
    "    :param test_features: 测试集（但实际上经常输入验证集）的feature\n",
    "    :param test_labels:测试集（但实际上经常输入验证集）的label\n",
    "    :param num_epochs:迭代次数\n",
    "    :param learning_rate:学习率\n",
    "    :param weight_decay:\n",
    "    :param batch_size:批量大小\n",
    "    :return:每大步的训练lgrmse 和 测试lgrmse\n",
    "    '''\n",
    "    train_ls, test_ls = [], [] # 用来记录每步的logRMSE\n",
    "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
    "    # 这里使用的是Adam优化算法\n",
    "    optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                 lr = learning_rate,\n",
    "                                 weight_decay = weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
    "        if test_labels is not None: # 如果有testset输入近来的话\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
    "    test_pred = net(test_features)\n",
    "    test_pred = test_pred.detach().numpy()\n",
    "\n",
    "    return train_ls, test_ls, test_pred\n",
    "\n",
    "# 为K-fold 划分数据集\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    '''\n",
    "    为K-fold 划分数据集\n",
    "    :param k: k-fold 的k\n",
    "    :param i: 第i个fold作为validation set\n",
    "    :param X: 原始训练集（未划分训练验证的）的整个feature\n",
    "    :param y: 原始训练集的整个label\n",
    "    :return: 交叉检验使用的训练集和验证集\n",
    "    '''\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k # 每个fold的规模\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size) # 一个fold的索引\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "        # i-th fold是validation set，其他作为TrainSet\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,\n",
    "           batch_size):\n",
    "    '''\n",
    "\n",
    "    :param k: number of folds\n",
    "    :param X_train: total train set features\n",
    "    :param y_train: total train labels\n",
    "    :param num_epochs: No. of displays\n",
    "    :param learning_rate: learning rate\n",
    "    :param weight_decay:\n",
    "    :param batch_size: size of batch\n",
    "    :return: Trainlogmse和Validationlogmse的平均值（把k次算到的取平均，更重要的是后者）\n",
    "    '''\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        # 依次对每一个fold当作测试集，剩余的当作训练集\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net()\n",
    "        train_ls, valid_ls,_ = train(net, *data, num_epochs, learning_rate,\n",
    "                                   weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        if i == 0:\n",
    "            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n",
    "                     xlabel='epoch', ylabel='lgrmse', xlim=[1, num_epochs],\n",
    "                     legend=['train', 'valid'], yscale='log')\n",
    "        print(f'fold {i + 1}, train log rmse {float(train_ls[-1]):f}, '\n",
    "              f'valid log rmse {float(valid_ls[-1]):f}')\n",
    "    return train_l_sum / k, valid_l_sum / k\n",
    "\n",
    "def train_and_pred(train_features, test_features, train_labels, test_labels,\n",
    "                   num_epochs, lr, weight_decay, batch_size):\n",
    "    net = get_net()\n",
    "    train_ls, test_ls,test_pred = train(net, train_features, train_labels, test_features, test_labels,\n",
    "                        num_epochs, lr, weight_decay, batch_size)\n",
    "    return train_ls, test_ls, test_pred\n",
    "\n",
    "__name__ = 'TrainPred'\n",
    "if __name__ == 'CrossValidation':\n",
    "    k, num_epochs, lr, weight_decay, batch_size = 5, 100, 0.05, 0, 1000\n",
    "    train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\n",
    "                              weight_decay, batch_size)\n",
    "    print(f'{k}-折验证: 平均训练log rmse: {float(train_l):f}, '\n",
    "          f'平均验证log rmse: {float(valid_l):f}')\n",
    "\n",
    "elif __name__ == 'TrainPred':\n",
    "    k, num_epochs, lr, weight_decay, batch_size = 5, 100, 0.05, 0, 1000\n",
    "    train_ls, test_ls, test_pred = train_and_pred(train_features, test_features, train_labels, test_labels,\n",
    "                   num_epochs, lr, weight_decay, batch_size)\n",
    "    print(f' 训练log rmse: {float(train_ls[-1]):f}, '\n",
    "          f'测试log rmse: {float(test_ls[-1]):f},')\n",
    "    test_pred = test_pred.ravel()\n",
    "    print(test_pred)\n",
    "    print(guideprice_test)\n",
    "    # test_pred:numpy.ndarray\n",
    "    # guideprice_test :numpy.ndarray\n",
    "    \n",
    "else:\n",
    "    print('error main command')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "0       7.910000\n",
      "1       9.500000\n",
      "2       5.700100\n",
      "3       4.250000\n",
      "4       8.150000\n",
      "...          ...\n",
      "31873  10.700000\n",
      "31874   7.680000\n",
      "31875  27.000000\n",
      "31876  26.639999\n",
      "31877   5.310000\n",
      "\n",
      "[31878 rows x 1 columns]\n",
      "           0\n",
      "0      16.78\n",
      "1      19.28\n",
      "2      12.48\n",
      "3      10.99\n",
      "4      12.98\n",
      "...      ...\n",
      "31873  13.08\n",
      "31874  13.48\n",
      "31875  48.80\n",
      "31876  41.53\n",
      "31877   7.48\n",
      "\n",
      "[31878 rows x 1 columns]\n",
      "               0\n",
      "0       8.340372\n",
      "1       9.611574\n",
      "2       3.708205\n",
      "3       2.739346\n",
      "4       9.384337\n",
      "...          ...\n",
      "31873  10.257640\n",
      "31874   8.907538\n",
      "31875  27.446644\n",
      "31876  25.006922\n",
      "31877   3.879147\n",
      "\n",
      "[31878 rows x 1 columns]\n",
      "               0          0      0\n",
      "0       8.340372   7.910000  16.78\n",
      "1       9.611574   9.500000  19.28\n",
      "2       3.708205   5.700100  12.48\n",
      "3       2.739346   4.250000  10.99\n",
      "4       9.384337   8.150000  12.98\n",
      "...          ...        ...    ...\n",
      "31873  10.257640  10.700000  13.08\n",
      "31874   8.907538   7.680000  13.48\n",
      "31875  27.446644  27.000000  48.80\n",
      "31876  25.006922  26.639999  41.53\n",
      "31877   3.879147   5.310000   7.48\n",
      "\n",
      "[31878 rows x 3 columns]\n",
      "              0\n",
      "0      0.025648\n",
      "1      0.005787\n",
      "2      0.159607\n",
      "3      0.137457\n",
      "4      0.095095\n",
      "...         ...\n",
      "31873  0.033820\n",
      "31874  0.091064\n",
      "31875  0.009153\n",
      "31876  0.039323\n",
      "31877  0.191290\n",
      "\n",
      "[31878 rows x 1 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[0.84585511]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "Trade_price = pd.DataFrame(test_labels.numpy()) # trade price\n",
    "print(Trade_price)\n",
    "Guide_price = pd.DataFrame(guideprice_test) #guide price\n",
    "Pred_price = pd.DataFrame(test_pred) # prediction price\n",
    "print(Guide_price)\n",
    "print(Pred_price)\n",
    "data = pd.concat((Pred_price,Trade_price,Guide_price), axis = 1)\n",
    "# gap = abs(pred_price-trade price)/guide price\n",
    "print(data)\n",
    "\n",
    "# write\n",
    "writer = pd.ExcelWriter('A.xlsx')\n",
    "data.to_excel(writer,'page_1',float_format = '%.5f')\n",
    "writer.save()\n",
    "\n",
    "gap = abs(Pred_price-Trade_price)/Guide_price\n",
    "print(gap)\n",
    "print(type(gap))\n",
    "rate = sum(gap.values<=0.10)/(nData-nTrain)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数 w： tensor([-0.0114, -0.0070,  0.0276,  0.0032,  0.0226])\n",
      "bias term b： tensor([-0.0157])\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "w = net[0].weight.data\n",
    "print('参数 w：', w.reshape(in_features)[0:5])\n",
    "b = net[0].bias.data\n",
    "print('bias term b：', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
